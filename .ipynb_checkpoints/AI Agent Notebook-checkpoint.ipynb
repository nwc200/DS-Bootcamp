{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!py -m pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.callbacks import StdOutCallbackHandler\n",
    "import requests\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.globals import set_debug\n",
    "\n",
    "# set_debug(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAVILY_API_KEY = os.environ[\"TAVILY_API_KEY\"]\n",
    "os.environ[\"TAVILY_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use llama3.1 and test if it is working\n",
    "model = OllamaLLM(model=\"llama3.1\", temperature=0)\n",
    "model.invoke(\"Come up with 10 names for a song about parrots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "\n",
    "@tool()\n",
    "def get_number_active_cpf_members_and_employers(input: str) -> str:\n",
    "    \"\"\"Gets the number of all, Central Provident Fund (CPF) Members & Active Employers\"\"\"\n",
    "\n",
    "    dataset_dict = {\n",
    "        \"active_member\": \"d_89dd4e5486fe3bb3b0c620cc6f787cdc\",\n",
    "        \"active_employer\": \"d_bccb6829056e74f8a87b99c1bdb3e3ab\",\n",
    "        \"member\": \"d_0014a7b5fa44981567b4c99c7a126630\"\n",
    "    }\n",
    "\n",
    "    # Find out what type of question the user is asking\n",
    "    question_classification_chain = model.invoke(f\"\"\"You are a chatbot tasked to identify if the following user query is asking for the \n",
    "                 1) Number of Central Provident Fund (CPF) active members. If user is asking for this, respond with active_member\n",
    "                 2) Number of Central Provident Fund (CPF) active employers. If user is asking for this, respond with active_employer\n",
    "                 3) Number of Central Provident Fund (CPF) members. If user is asking for this, respond with member\n",
    "\n",
    "                 If you do not have the answer respond with 'I don't know'.\n",
    "                                \n",
    "                Query: {input}\"\"\")\n",
    "    \n",
    "    if question_classification_chain not in dataset_dict:\n",
    "        return \"I don't know\"\n",
    "    else:\n",
    "        datasetId = dataset_dict[question_classification_chain]\n",
    "\n",
    "    # Find out what year and quarter the user is asking for\n",
    "    year_quarter_chain = model.invoke(f\"\"\"You are a chatbot tasked to identify the year and quarter from the user query \n",
    "                 1) If you do not know the year reply 2024\n",
    "                 2) If you do not know the quarter reply Q1\n",
    "\n",
    "                 Format your answer in the followng format YYYY-QQ. Only reply with the YYYY-QQ.\n",
    "                                \n",
    "                Query: {input}\"\"\")\n",
    "\n",
    "    year_quarter_chain = year_quarter_chain.strip()\n",
    "     \n",
    "    url = \"https://data.gov.sg/api/action/datastore_search\"\n",
    "    response = requests.get(url, params={\"resource_id\": datasetId})\n",
    "\n",
    "    result = \"I don't know\"\n",
    "    for i in response.json()['result']['records']:\n",
    "        if i['qtr'] == year_quarter_chain:\n",
    "            result = i[list(i.keys())[2]]\n",
    "    \n",
    "\n",
    "    return f\"\\nObservation: {result}\"\n",
    "\n",
    "\n",
    "@tool()\n",
    "def web_search(input: str) -> str:\n",
    "    \"\"\"Runs web search for generic Central Provident Fund (CPF) related questions\"\"\"\n",
    "    web_search_tool = TavilySearchResults()\n",
    "\n",
    "    try:\n",
    "        docs = web_search_tool.invoke({\"query\": input})\n",
    "    except Exception as e:\n",
    "        return f\"Something went wrong using Tavily, {e}\"\n",
    "    \n",
    "\n",
    "    output = model.invoke(f\"\"\"You are text summarization tool that will ONLY help to summarize relevant information.\n",
    "        Use following piece of context to answer the question. \n",
    "        If you don't know the answer or there is no relevant context, just say you don't know. \n",
    "        Keep the answer within 5 sentences and concise.\n",
    "\n",
    "        Context: {docs[0:3]}\n",
    "        Question: {input}\n",
    "        Answer: \n",
    "\n",
    "        \"\"\")\n",
    "\n",
    "    \n",
    "    return f\"\\nObservation: {output}\"\n",
    "\n",
    "\n",
    "@tool(return_direct=True)\n",
    "def no_answer(input: str) -> str:\n",
    "    \"\"\"Come up with a generic fallback response when you get asked a question not related to Central Provident Fund (CPF)\"\"\"\n",
    "\n",
    "    fallback = model.invoke(f\"You are a chatbot that does not have sufficient information to answer the user's question. Please come up with a fallback response apologising to the user that you were not able to answer their question.\\n===CONVERSATION=== USER: {input}. CHATBOT:\"\n",
    "                            )\n",
    "    return fallback\n",
    "\n",
    "\n",
    "tools = [\n",
    "    get_number_active_cpf_members_and_employers,\n",
    "    web_search,\n",
    "    no_answer\n",
    "]\n",
    "\n",
    "#get_number_active_cpf_members_and_employers.invoke(\"how many active cpf members are there?\")\n",
    "#web_search.invoke(\"what is CPF?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.template = \"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Thought: you should always think about what to do. If you have enough information, give your Final Answer. If you don't know, use the no_answer tool.\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the Action Input is the EXACT verbatim of the Question asked. Do not add or change the Question.\n",
    "Observation: Additional information given by the tool that can be used in the Final Answer.\n",
    "\n",
    "This Thought/Action/Action Input/Observation can repeat if you do not have enough information.\n",
    "\n",
    "Once you have enough information to answer the user question, do the following:\n",
    "Thought: I now know the final answer\n",
    "Final Answer: ONLY give your final answer to the question that was asked.\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMessageHistory(session_id=\"test-session\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_react_agent(model, tools, prompt)\n",
    "\n",
    "handler = StdOutCallbackHandler()\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, max_iterations=3, verbose=True, return_intermediate_steps=True, callbacks=[handler])\n",
    "\n",
    "\n",
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    lambda session_id: memory,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke(\n",
    "    {\"input\": \"How old do I need to be to claim CPF?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke(\n",
    "    {\"input\": \"What is CPF?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke(\n",
    "    {\"input\": \"How much CPF do employers need to contribute?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke(\n",
    "    {\"input\": \"What is the weather in Singapore tommorow?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_chat_history.invoke(\n",
    "        {\"input\": \"How many CPF active users are there?\"},\n",
    "        config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
